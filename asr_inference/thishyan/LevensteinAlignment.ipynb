{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca54795f-4c4a-4234-af76-a4ad04a98220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "from espnet2.text.build_tokenizer import build_tokenizer\n",
    "from espnet2.text.token_id_converter import TokenIDConverter\n",
    "\n",
    "import jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108aaa2a-a103-4927-b27c-b18c9314c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_dir = \"/home/pb_deployment/espnet/asr_inference/model_files/e_branchformer_librispeech/\"\n",
    "asr_config_path = os.path.join(model_root_dir, \"exp/asr_train_asr_e_branchformer_raw_en_bpe5000_sp/config.yaml\")\n",
    "bpe_model_path = os.path.join(model_root_dir,\"data/en_token_list/bpe_unigram5000/bpe.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd1ce6c-1618-4e8a-bdc4-13a423653eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TruCLeS_Tokenizer:\n",
    "    def __init__(self, asr_config_path, bpe_model_path):\n",
    "        self.asr_config_path = asr_config_path\n",
    "        self.bpe_model_path = bpe_model_path\n",
    "        self.tokenizer = build_tokenizer(\n",
    "            token_type='bpe',\n",
    "            bpemodel=bpe_model_path  \n",
    "        )\n",
    "        with open(self.asr_config_path, 'r') as file:\n",
    "            config_data = yaml.safe_load(file)\n",
    "        self.tokens_list = config_data.get('token_list', [])\n",
    "        self.tokenIDConvertor = TokenIDConverter(token_list = self.tokens_list)\n",
    "\n",
    "        self.ids = dict(zip(self.tokens_list, [i for i in range(len(self.tokens_list))]))\n",
    "\n",
    "    def text2ids(self, text):\n",
    "        tokenized = self.tokenizer.text2tokens(text)\n",
    "        ids = self.tokenIDConvertor.tokens2ids(tokenized)\n",
    "        return ids\n",
    "    \n",
    "    def ids2text(self, ids):\n",
    "        tokenized = self.tokenIDConvertor.ids2tokens(ids)\n",
    "        text = self.tokenizer.tokens2text(tokenized)\n",
    "        return text\n",
    "\n",
    "    def text2tokens(self, text):\n",
    "        return self.tokenizer.text2tokens(text)\n",
    "        \n",
    "    def tokens2text(self, tokens):\n",
    "        return self.tokenizer.tokens2text(tokens)\n",
    "\n",
    "    def tokens2ids(self, tokens):\n",
    "        return self.tokenIDConvertor.tokens2ids(tokens)\n",
    "\n",
    "    def ids2tokens(self, ids):\n",
    "        return self.tokenIDConvertor.ids2tokens(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "404bb4a1-dbb5-409c-9082-7e4f11aa0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TruCLeS_Tokenizer(asr_config_path, bpe_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3aa27711-6f59-44b3-b4b8-545e1a6160bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 1\n",
      "REF: HELLO  THIS IS THISHYAN RAJ\n",
      "HYP: HELLO THISH IS   THIYAN ***\n",
      "               S           S   D\n",
      "\n",
      "[['▁HE', 'LL', 'O'], ['▁THIS', ''], ['▁IS'], ['', '▁THIS', 'HY', 'AN']]\n"
     ]
    }
   ],
   "source": [
    "ref = \"HELLO THIS IS THISHYAN RAJ\" \n",
    "hyp = \"HELLO THISH IS THIYAN\"\n",
    "print(jiwer.visualize_alignment(jiwer.process_words(ref, hyp), skip_correct=False, show_measures=False))\n",
    "\n",
    "def getAlignedHyp(ref, hyp, tokenizer = tokenizer):\n",
    "    wOut = jiwer.process_words(ref, hyp)\n",
    "    wRefList = wOut.references[0]\n",
    "    wHypList = wOut.hypotheses[0]\n",
    "    wAligns = wOut.alignments[0]\n",
    "    tokenizedWRefList = tokenizer.text2tokens(wRefList)\n",
    "    tokenizedWHypList = tokenizer.text2tokens(wHypList)\n",
    "    \n",
    "    align_list = []\n",
    "    for wAlign in wAligns:\n",
    "        if wAlign.type == \"equal\":\n",
    "            align_list = align_list + tokenizedWHypList[wAlign.hyp_start_idx:wAlign.hyp_end_idx]\n",
    "        elif wAlign.type == \"insert\":\n",
    "            align_list.append([])\n",
    "        elif wAlign.type == \"substitute\":\n",
    "            hypWords = tokenizedWHypList[wAlign.hyp_start_idx:wAlign.hyp_end_idx]\n",
    "            refWords = tokenizedWRefList[wAlign.ref_start_idx:wAlign.ref_end_idx]\n",
    "            word_list = []\n",
    "            for hypWord, refWord in zip(hypWords, refWords):\n",
    "                tOut = jiwer.process_words(\" \".join(refWord), \" \".join(hypWord))\n",
    "                tRefList = tOut.references[0]\n",
    "                tHypList = tOut.hypotheses[0]\n",
    "                tAligns = tOut.alignments[0]\n",
    "                for tAlign in tAligns:\n",
    "                    if tAlign.type == \"equal\":\n",
    "                        word_list = word_list + tHypList[tAlign.hyp_start_idx:tAlign.hyp_end_idx]\n",
    "                    elif tAlign.type == \"substitute\":\n",
    "                        word_list = word_list + tRefList[tAlign.ref_start_idx:tAlign.ref_end_idx]\n",
    "                    elif tAlign.type == \"insert\":\n",
    "                        word_list.append(\"\")\n",
    "            align_list = align_list + [word_list]\n",
    "    return align_list\n",
    "\n",
    "align_list = getAlignedHyp(ref, hyp)\n",
    "print(align_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "38f36e59-93bc-4254-b2a2-7c9c2676da01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 1\n",
      "2 1\n",
      "3 1\n",
      "4 0\n",
      "5 1\n",
      "6 0\n",
      "7 1\n",
      "8 1\n",
      "9 1\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for word in align_list:\n",
    "    if len(word) != 0:\n",
    "        for tok in word:\n",
    "            if tok!=\"\":\n",
    "                print(i, 1)\n",
    "            else:\n",
    "                print(i, 0)\n",
    "            i += 1\n",
    "    else:\n",
    "        print(i, 0)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601f937-adcd-4aa9-9cae-a87cc748a53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
